# Robotic Hand Control EMG Simulation

## Description
This project implements a robotic hand control system using Electromyography (EMG) signal simulation and the GRABMyoda dataset. The system captures EMG signals, processes them with Python, and uses the Mediapipe framework for hand landmark detection to map muscle activation patterns to robotic hand movements.

## Dataset
We use the GRABMyoda dataset from PhysioNet:
https://physionet.org/content/grabmyo/1.1.0/

## Media

![Demo Image 1](./media/images/img1.jpeg)  
![Demo Image 2](./media/images/img2.jpeg)  
![Demo Image 3](./media/images/img3.jpeg)  
![Demo Image 4](./media/images/img4.jpeg)

Watch demo video:

- [Demo Video 1](./media/videos/video1.mp4)

## Features
- **EMG Simulation:** Preprocessed EMG signals from the GRABMyoda dataset.
- **Hand Landmark Detection:** Uses Mediapipe Hands for real-time hand keypoint detection.  
  Documentation: https://google.github.io/mediapipe/solutions/hands
- **Mapping Algorithm:** Converts landmark coordinates and EMG patterns into servo commands.
- **Visualization:** Real-time plotting of EMG signals and detected hand landmarks.

## Installation
1. **Clone the repository**
   ```bash
   git clone https://github.com/Nonurt/Robotic-Hand-Control-Emg-Simulation-GRABMyo-dataset-.git
   cd Robotic-Hand-Control-Emg-Simulation-GRABMyo-dataset-
   ```
2. **Create and activate a virtual environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```
3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## Usage
1. Download the GRABMyoda dataset from PhysioNet and place it under `data/GRABMyoda/`.
2. Run the EMG preprocessing script:
   ```bash
   python scripts/emg_preprocess.py --input data/GRABMyoda --output processed/
   ```
3. Start the hand detection and control application:
   ```bash
   python hand_control.py
   ```

## Project Structure
```
Robotic-Hand-Control-Emg-Simulation-GRABMyo-dataset-/
├── data/                  # GRABMyoda raw and processed data
├── scripts/               # Preprocessing and utility scripts
│   ├── emg_preprocess.py
│   └── utils.py
├── models/                # Trained mapping models (if any)
├── media/                 # Demo videos and images
│   ├── videos/
│   └── images/
├── hand_control.py        # Main application for hand detection and control
├── requirements.txt       # Project dependencies
└── README.md              # This file
```

THE README İS WRİTTEN BY CHATGPT,  https://physionet.org/content/grabmyo/1.1.0/ THİS PROJECT CAN BE MADE BECAUSE GRABMYO DATASET AND MEDİAPİE EXİSTED.
This project is released under the MIT License.

---
*The README and requirements files were generated by AI (ChatGPT)*
